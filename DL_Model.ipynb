{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "DL_Model.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlIJeMTCQQ9S",
        "colab_type": "text"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-cG4JqrQQ9V",
        "colab_type": "text"
      },
      "source": [
        "### Loading Features and descriptions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Px-ovreuzCdH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "2b3d8068-df09-4eda-a91e-ef16142ca5f0"
      },
      "source": [
        "!wget https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_text.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-11 09:32:58--  https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_text.zip\n",
            "Resolving github.com (github.com)... 13.229.188.59\n",
            "Connecting to github.com (github.com)|13.229.188.59|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/124585957/47f52b80-3501-11e9-8d2e-dd69a21a4362?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20191111%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20191111T093258Z&X-Amz-Expires=300&X-Amz-Signature=095b7dfceecc399043b3fc519db662a484c2258595c99d20a48a436ae5279e74&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3DFlickr8k_text.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2019-11-11 09:32:59--  https://github-production-release-asset-2e65be.s3.amazonaws.com/124585957/47f52b80-3501-11e9-8d2e-dd69a21a4362?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20191111%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20191111T093258Z&X-Amz-Expires=300&X-Amz-Signature=095b7dfceecc399043b3fc519db662a484c2258595c99d20a48a436ae5279e74&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3DFlickr8k_text.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.217.43.28\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.217.43.28|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2340801 (2.2M) [application/octet-stream]\n",
            "Saving to: ‘Flickr8k_text.zip’\n",
            "\n",
            "Flickr8k_text.zip   100%[===================>]   2.23M  1.47MB/s    in 1.5s    \n",
            "\n",
            "2019-11-11 09:33:01 (1.47 MB/s) - ‘Flickr8k_text.zip’ saved [2340801/2340801]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VICJPdCMzCZJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip Flickr8k_text.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5WOJn_nzCX2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir dataset dataset/text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D92r9tVpzCUq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv *.txt dataset/text/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6TkpjDvzCSe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv dataset/text/descriptions.txt dataset/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NpKHCv9zCPN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv features.pkl dataset/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gjJvlPM2PlT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-10T13:32:32.413977Z",
          "start_time": "2019-11-10T13:32:32.411491Z"
        },
        "id": "uOX1moqmQQ9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pickle import load"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-10T13:32:32.422905Z",
          "start_time": "2019-11-10T13:32:32.416105Z"
        },
        "id": "1--IXIg4QQ9f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_doc(filename):\n",
        "    with open(filename, 'r') as file:\n",
        "        text = file.read()\n",
        "    \n",
        "    return text\n",
        "\n",
        "def load_set(filename):\n",
        "    doc = load_doc(filename)\n",
        "    dataset = list()\n",
        "    \n",
        "    for line in doc.split('\\n'):\n",
        "        if len(line) < 1:\n",
        "            continue\n",
        "        identifier = line.split('.')[0]\n",
        "        dataset.append(identifier)\n",
        "    return set(dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-10T13:32:32.428545Z",
          "start_time": "2019-11-10T13:32:32.424177Z"
        },
        "id": "cUZcq-G7QQ9j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_clean_descriptions(filename, dataset):\n",
        "    \n",
        "    doc = load_doc(filename)\n",
        "    descriptions = dict()\n",
        "    \n",
        "    for line in doc.split('\\n'):\n",
        "        tokens = line.split()\n",
        "        image_id, image_desc = tokens[0], tokens[1:]\n",
        "        \n",
        "        if image_id in dataset:\n",
        "            if image_id not in descriptions:\n",
        "                descriptions[image_id] = list()\n",
        "            desc = 'startseq ' + ' '.join(image_desc) + ' endseq'\n",
        "            \n",
        "            descriptions[image_id].append(desc)\n",
        "    return descriptions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-10T13:32:32.433974Z",
          "start_time": "2019-11-10T13:32:32.429765Z"
        },
        "id": "KLYJUjZ_QQ9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_photo_features(filename, dataset):\n",
        "    all_features = load(open(filename, 'rb'))\n",
        "    features = {k:all_features[k] for k in dataset}\n",
        "    return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-10T13:32:32.799955Z",
          "start_time": "2019-11-10T13:32:32.435282Z"
        },
        "id": "PoxODmeEQQ9v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d42f0e1e-a0b1-4629-e377-eda0de1a8c7d"
      },
      "source": [
        "# load training dataset (6K)\n",
        "filename = 'dataset/text/Flickr_8k.trainImages.txt'\n",
        "train = load_set(filename)\n",
        "print('Dataset: %d' % len(train))\n",
        "# descriptions\n",
        "train_descriptions = load_clean_descriptions('dataset/descriptions.txt', train)\n",
        "print('Descriptions: train=%d' % len(train_descriptions))\n",
        "# photo features\n",
        "train_features = load_photo_features('dataset/features.pkl', train)\n",
        "print('Photos: train=%d' % len(train_features))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset: 6000\n",
            "Descriptions: train=6000\n",
            "Photos: train=6000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5dBZvGeQQ91",
        "colab_type": "text"
      },
      "source": [
        "### Encoding Descriptions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-10T13:32:34.024461Z",
          "start_time": "2019-11-10T13:32:32.802075Z"
        },
        "id": "8VWTE-RjQQ92",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "1b6e3e83-cac7-40ca-8073-adf2435159f3"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-10T13:32:34.031097Z",
          "start_time": "2019-11-10T13:32:34.027879Z"
        },
        "id": "XVUw68QyQQ95",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_lines(descriptions):\n",
        "    all_desc = list()\n",
        "    for key in descriptions.keys():\n",
        "        [all_desc.append(d) for d in descriptions[key]]\n",
        "    return all_desc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-10T13:32:34.044030Z",
          "start_time": "2019-11-10T13:32:34.032485Z"
        },
        "id": "zqsTTCnMQQ98",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_tokenizer(descriptions):\n",
        "    lines = to_lines(descriptions)\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(lines)\n",
        "    return tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-10T13:32:34.473999Z",
          "start_time": "2019-11-10T13:32:34.047581Z"
        },
        "id": "7acHVP_gQQ9_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4f7fec3d-55f2-47b9-985d-618c15373580"
      },
      "source": [
        "tokenizer = create_tokenizer(train_descriptions)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('Vocabulary Size: %d' % vocab_size)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Size: 7579\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-10T13:32:34.478356Z",
          "start_time": "2019-11-10T13:32:34.475354Z"
        },
        "id": "VkjDwX_4QQ-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "from keras.utils import plot_model\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Dropout\n",
        "from keras.layers.merge import add\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gD1f98sj8Vh",
        "colab_type": "text"
      },
      "source": [
        "## Data Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-10T13:32:34.487357Z",
          "start_time": "2019-11-10T13:32:34.479473Z"
        },
        "id": "RrZcNNzBQQ-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data generator, intended to be used in a call to model.fit_generator()\n",
        "def data_generator(descriptions, photos, tokenizer, max_length, vocab_size):\n",
        "    # loop for ever over images\n",
        "    while 1:\n",
        "        for key, desc_list in descriptions.items():\n",
        "            # retrieve the photo feature\n",
        "            photo = photos[key][0]\n",
        "            in_img, in_seq, out_word = create_sequences(tokenizer, max_length, desc_list, photo, vocab_size)\n",
        "            yield [[in_img, in_seq], out_word]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-10T13:32:34.497130Z",
          "start_time": "2019-11-10T13:32:34.489546Z"
        },
        "id": "d0Fm6T6qQQ-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_sequences(tokenizer, max_length, desc_list, photo, vocab_size):\n",
        "    X1, X2, y = list(), list(), list()\n",
        "    \n",
        "    for desc in desc_list:\n",
        "        seq = tokenizer.texts_to_sequences([desc])[0]\n",
        "\n",
        "        for i in range(1, len(seq)):\n",
        "            in_seq, out_seq = seq[:i], seq[i]\n",
        "\n",
        "            in_seq = pad_sequences([in_seq], maxlen = max_length)[0]\n",
        "            out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
        "\n",
        "            X1.append(photo)\n",
        "            X2.append(in_seq)\n",
        "            y.append(out_seq)\n",
        "    return np.array(X1), np.array(X2), np.array(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-10T13:32:34.505126Z",
          "start_time": "2019-11-10T13:32:34.498654Z"
        },
        "id": "OUgLSdY9QQ-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def max_length(descriptions):\n",
        "    lines = to_lines(descriptions)\n",
        "    return max(len(d.split()) for d in lines)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xp7kEivIkCJI",
        "colab_type": "text"
      },
      "source": [
        "## Defining Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-10T13:32:34.517841Z",
          "start_time": "2019-11-10T13:32:34.508200Z"
        },
        "id": "7YSOxC3zQQ-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def define_model(vocab_size, max_length):\n",
        "    inputs1 = Input(shape=(4096,))\n",
        "    fe1 = Dropout(0.5)(inputs1)\n",
        "    fe2 = Dense(256, activation='relu')(fe1)\n",
        "    \n",
        "    inputs2 = Input(shape=(max_length,))\n",
        "    se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n",
        "    se2 = Dropout(0.5)(se1)\n",
        "    se3 = LSTM(256)(se2)\n",
        "\n",
        "    decoder1 = add([fe2, se3])\n",
        "    decoder2 = Dense(256, activation='relu')(decoder1)\n",
        "    outputs = Dense(vocab_size, activation='softmax')(decoder2)\n",
        "    \n",
        "    model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "    print(model.summary())\n",
        "    plot_model(model, to_file='model.png', show_shapes=True)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5KGYKhNkKo6",
        "colab_type": "text"
      },
      "source": [
        "## Training Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-10T13:32:35.768372Z",
          "start_time": "2019-11-10T13:32:34.529848Z"
        },
        "scrolled": true,
        "id": "bap_OPczQQ-T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        },
        "outputId": "d2d0cac1-eaff-4e74-c2c8-ca323e08e02a"
      },
      "source": [
        "# load training dataset (6K)\n",
        "filename = 'dataset/text/Flickr_8k.trainImages.txt'\n",
        "train = load_set(filename)\n",
        "print('Dataset: %d' % len(train))\n",
        "# descriptions\n",
        "train_descriptions = load_clean_descriptions('dataset/descriptions.txt', train)\n",
        "print('Descriptions: train=%d' % len(train_descriptions))\n",
        "# photo features\n",
        "train_features = load_photo_features('dataset/features.pkl', train)\n",
        "print('Photos: train=%d' % len(train_features))\n",
        "# prepare tokenizer\n",
        "tokenizer = create_tokenizer(train_descriptions)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('Vocabulary Size: %d' % vocab_size)\n",
        "# determine the maximum sequence length\n",
        "max_length = max_length(train_descriptions)\n",
        "print('Description Length: %d' % max_length)\n",
        " \n",
        "# define the model\n",
        "model = define_model(vocab_size, max_length)\n",
        "# train the model, run epochs manually and save after each epoch\n",
        "epochs = 20\n",
        "steps = len(train_descriptions)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset: 6000\n",
            "Descriptions: train=6000\n",
            "Photos: train=6000\n",
            "Vocabulary Size: 7579\n",
            "Description Length: 34\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3239: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 34)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_1 (InputLayer)            (None, 4096)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 34, 256)      1940224     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 4096)         0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 34, 256)      0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 256)          1048832     dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 256)          525312      dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 256)          0           dense_1[0][0]                    \n",
            "                                                                 lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 256)          65792       add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 7579)         1947803     dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 5,527,963\n",
            "Trainable params: 5,527,963\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZzR_oLFQ8sV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "augmented_checkpoint = ModelCheckpoint('augmented_best_model.hdf5',  # model filename\n",
        "                                       monitor='val_loss',  # quantity to monitor\n",
        "                                       verbose=1,  # verbosity - 0 or 1\n",
        "                                       save_best_only=True,  # The latest best model will not be overwritten\n",
        "                                       mode='auto')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sfpq_n_fRDOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator = data_generator(train_descriptions, train_features, tokenizer, max_length, vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wk_BKO8PUzdq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "525e4aed-6b4e-44d3-e4ab-8b6ed5ebde66"
      },
      "source": [
        "history = model.fit_generator(generator, epochs=20, callbacks=[augmented_checkpoint], steps_per_epoch=steps, verbose=1)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "6000/6000 [==============================] - 516s 86ms/step - loss: 4.6247\n",
            "Epoch 2/20\n",
            "   2/6000 [..............................] - ETA: 8:09 - loss: 3.7451"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:707: RuntimeWarning: Can save best model only with val_loss available, skipping.\n",
            "  'skipping.' % (self.monitor), RuntimeWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "6000/6000 [==============================] - 510s 85ms/step - loss: 3.8785\n",
            "Epoch 3/20\n",
            "6000/6000 [==============================] - 489s 82ms/step - loss: 3.6296\n",
            "Epoch 4/20\n",
            "6000/6000 [==============================] - 487s 81ms/step - loss: 3.4798\n",
            "Epoch 5/20\n",
            "6000/6000 [==============================] - 489s 82ms/step - loss: 3.3852\n",
            "Epoch 6/20\n",
            "6000/6000 [==============================] - 490s 82ms/step - loss: 3.3078\n",
            "Epoch 7/20\n",
            "6000/6000 [==============================] - 486s 81ms/step - loss: 3.2542\n",
            "Epoch 8/20\n",
            "6000/6000 [==============================] - 483s 81ms/step - loss: 3.2116\n",
            "Epoch 9/20\n",
            "6000/6000 [==============================] - 485s 81ms/step - loss: 3.1764\n",
            "Epoch 10/20\n",
            "6000/6000 [==============================] - 485s 81ms/step - loss: 3.1515\n",
            "Epoch 11/20\n",
            "6000/6000 [==============================] - 485s 81ms/step - loss: 3.1278\n",
            "Epoch 12/20\n",
            "6000/6000 [==============================] - 486s 81ms/step - loss: 3.1109\n",
            "Epoch 13/20\n",
            "6000/6000 [==============================] - 487s 81ms/step - loss: 3.0929\n",
            "Epoch 14/20\n",
            "6000/6000 [==============================] - 486s 81ms/step - loss: 3.0842\n",
            "Epoch 15/20\n",
            "6000/6000 [==============================] - 486s 81ms/step - loss: 3.0680\n",
            "Epoch 16/20\n",
            "6000/6000 [==============================] - 489s 82ms/step - loss: 3.0633\n",
            "Epoch 17/20\n",
            "6000/6000 [==============================] - 489s 81ms/step - loss: 3.0554\n",
            "Epoch 18/20\n",
            "6000/6000 [==============================] - 491s 82ms/step - loss: 3.0503\n",
            "Epoch 19/20\n",
            "6000/6000 [==============================] - 494s 82ms/step - loss: 3.0451\n",
            "Epoch 20/20\n",
            "6000/6000 [==============================] - 494s 82ms/step - loss: 3.0399\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrLHgVb1kPFb",
        "colab_type": "text"
      },
      "source": [
        "## Saving Tokenizer and Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bBrkljMfPim",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pickle import dump"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WN7SSXGBcxu9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('model.hdf5')\n",
        "dump(tokenizer, open('tokenizer.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UpbU6e0fh-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pickle import load\n",
        "from numpy import argmax\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from nltk.translate.bleu_score import corpus_bleu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXraepGlkSk7",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EwDGsJoekoA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# map an integer to a word\n",
        "def word_for_id(integer, tokenizer):\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == integer:\n",
        "\t\t\treturn word\n",
        "\treturn None\n",
        " \n",
        "# generate a description for an image\n",
        "def generate_desc(model, tokenizer, photo, max_length):\n",
        "\t# seed the generation process\n",
        "\tin_text = 'startseq'\n",
        "\t# iterate over the whole length of the sequence\n",
        "\tfor i in range(max_length):\n",
        "\t\t# integer encode input sequence\n",
        "\t\tsequence = tokenizer.texts_to_sequences([in_text])[0]\n",
        "\t\t# pad input\n",
        "\t\tsequence = pad_sequences([sequence], maxlen=max_length)\n",
        "\t\t# predict next word\n",
        "\t\tyhat = model.predict([photo,sequence], verbose=0)\n",
        "\t\t# convert probability to integer\n",
        "\t\tyhat = argmax(yhat)\n",
        "\t\t# map integer to word\n",
        "\t\tword = word_for_id(yhat, tokenizer)\n",
        "\t\t# stop if we cannot map the word\n",
        "\t\tif word is None:\n",
        "\t\t\tbreak\n",
        "\t\t# append as input for generating the next word\n",
        "\t\tin_text += ' ' + word\n",
        "\t\t# stop if we predict the end of the sequence\n",
        "\t\tif word == 'endseq':\n",
        "\t\t\tbreak\n",
        "\treturn in_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNMLlLGOdmMw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# evaluate the skill of the model\n",
        "def evaluate_model(model, descriptions, photos, tokenizer, max_length):\n",
        "\tactual, predicted = list(), list()\n",
        "\t# step over the whole set\n",
        "\tfor key, desc_list in descriptions.items():\n",
        "\t\t# generate description\n",
        "\t\tyhat = generate_desc(model, tokenizer, photos[key], max_length)\n",
        "\t\t# store actual and predicted\n",
        "\t\treferences = [d.split() for d in desc_list]\n",
        "\t\tactual.append(references)\n",
        "\t\tpredicted.append(yhat.split())\n",
        "\t# calculate BLEU score\n",
        "\tprint('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
        "\tprint('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n",
        "\tprint('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)))\n",
        "\tprint('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-aNiMJVdmBy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "777c4ba7-93c2-4a74-d597-948eb5156cb9"
      },
      "source": [
        "# load test set\n",
        "filename = 'dataset/text/Flickr_8k.testImages.txt'\n",
        "test = load_set(filename)\n",
        "print('Dataset: %d' % len(test))\n",
        "# descriptions\n",
        "test_descriptions = load_clean_descriptions('dataset/descriptions.txt', test)\n",
        "print('Descriptions: test=%d' % len(test_descriptions))\n",
        "# photo features\n",
        "test_features = load_photo_features('dataset/features.pkl', test)\n",
        "print('Photos: test=%d' % len(test_features))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset: 1000\n",
            "Descriptions: test=1000\n",
            "Photos: test=1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFy1Y8tgd1CO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "2d63237f-712a-44ea-c4a5-40a20c7dc708"
      },
      "source": [
        "evaluate_model(model, test_descriptions, test_features, tokenizer, max_length)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU-1: 0.506003\n",
            "BLEU-2: 0.265095\n",
            "BLEU-3: 0.180201\n",
            "BLEU-4: 0.083398\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BxcQDfdaSCv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyTEvaxYkWpH",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating on Single Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeoA9As-cbDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/09/example.jpg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyuPIEA5inQh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/How-to-Develop-a-Deep-Learning-Caption-Generation-Model-in-Python-from-Scratch.jpg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhBOKEMGjLbS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://unsplash.com/photos/OiACIz8F6ho/download?force=true"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiSBbUdQaSF5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_features(filename):\n",
        "\t# load the model\n",
        "\tmodel = VGG16()\n",
        "\t# re-structure the model\n",
        "\tmodel.layers.pop()\n",
        "\tmodel = Model(inputs=model.inputs, outputs=model.layers[-1].output)\n",
        "\t# load the photo\n",
        "\timage = load_img(filename, target_size=(224, 224))\n",
        "\t# convert the image pixels to a numpy array\n",
        "\timage = img_to_array(image)\n",
        "\t# reshape data for the model\n",
        "\timage = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "\t# prepare the image for the VGG model\n",
        "\timage = preprocess_input(image)\n",
        "\t# get features\n",
        "\tfeature = model.predict(image, verbose=0)\n",
        "\treturn feature"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqZLc5pGaR-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytTW3kOfaR8L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e7394fc2-0743-4db9-9995-b726944a01bd"
      },
      "source": [
        "photo = extract_features('example.jpg')\n",
        "# generate description\n",
        "description = generate_desc(model, tokenizer, photo, max_length)\n",
        "print(description)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "startseq two dogs are playing in the water endseq\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87yhA9tPaR1s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9ccec50a-e348-4861-80b2-8116812562e9"
      },
      "source": [
        "photo = extract_features('How-to-Develop-a-Deep-Learning-Caption-Generation-Model-in-Python-from-Scratch.jpg')\n",
        "# generate description\n",
        "description = generate_desc(model, tokenizer, photo, max_length)\n",
        "print(description)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "startseq two children are playing in the water endseq\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e7sPvIOaRwG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "36e80a23-d33e-4860-8cf1-512cebf7b899"
      },
      "source": [
        "photo = extract_features('example2.jpg')\n",
        "# generate description\n",
        "description = generate_desc(model, tokenizer, photo, max_length)\n",
        "print(description)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "startseq man in black shirt and hat is standing in front of an orange building endseq\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1G7WXXZ4aRuO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plyR4JxXaRqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}